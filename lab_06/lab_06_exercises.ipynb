{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "lab_06_exercises.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cAGoFS0haR_9",
        "C_o35m_GaR__",
        "Y-nTM2_slVtk"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w_V-_IFakMc"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ8ra7LvaR_8"
      },
      "source": [
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
        "\n",
        "##  Lab 06 - \"Autoencoder Neural Networks\"\n",
        "\n",
        "GSERM'21 course \"Deep Learning: Fundamentals and Applications\", University of St. Gallen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlP4X8FAjnGq"
      },
      "source": [
        "In the last lab we learned how to implement, train, and apply our first **Autoencoder Neural Network (AENN)** using a Python library named `PyTorch`. AENNs learn how to **encode** the input data into a low dimensional representation.  At the same time, the AENN learns how to **decode** the original data back from the encoded representation. The decoded data usually referred to as \"reconstruction\", should match the original input as closely as possible. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaDgayRvkvx1"
      },
      "source": [
        "Before we start let's watch a motivational video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPPVcpM_kx3J"
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "# GitHub Arctic Code Vault\n",
        "# YouTubeVideo('fzI9FNjXQ0o', width=800, height=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyAyOshlkXxg"
      },
      "source": [
        "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAGoFS0haR_9"
      },
      "source": [
        "## 1. Assignment Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRFQGKjaaR_9"
      },
      "source": [
        "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
        "\n",
        ">1. Understand the **basic concepts, intuitions and major building blocks** of autoencoder neural networks.\n",
        ">2. **Pre-process** categorical financial data to learn a model of its characteristics and pattern.\n",
        ">3. Apply autoencoder neural networks to **detect anomalies** in large-scale financial data.\n",
        ">4. **Interpret the detection results** of the network as well as its reconstruction loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_o35m_GaR__"
      },
      "source": [
        "## 2. Setup of the Jupyter Notebook Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L-grfyHaR__"
      },
      "source": [
        "As a next step, let's import the libraries needed throughout the lab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFOggrQ1aR__"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY-yJqQDaR__"
      },
      "source": [
        "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn`, `BT`, and a few utility libraries throughout the lab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pbn1RyHaR__"
      },
      "source": [
        "# import python data science and utility libraries\n",
        "import os, sys, itertools, urllib, io\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import pandas_datareader as dr\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SDydAL-aR__"
      },
      "source": [
        "Import the Python machine / deep learning libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiXsfLDXaR__"
      },
      "source": [
        "# pytorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torch.utils.data import dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfomiCMBaR__"
      },
      "source": [
        "Import Python plotting libraries and set general plotting parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QET0uwLHaSAA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn')\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.rcParams['figure.dpi']= 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jECsAH3aSAA"
      },
      "source": [
        "Enable notebook matplotlib inline plotting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxX1wggxaSAA"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0zOYLSEaSAA"
      },
      "source": [
        "Create a structure of notebook sub-directories to store the data as well as the trained neural network models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF793FPllJnX"
      },
      "source": [
        "if not os.path.exists('./data'): os.makedirs('./data')  # create data directory\n",
        "if not os.path.exists('./models'): os.makedirs('./models')  # create trained models directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ZhyjM8aSAA"
      },
      "source": [
        "Set a random seed value to obtain reproducable results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdGtYKP0aSAA"
      },
      "source": [
        "# init deterministic seed\n",
        "seed_value = 1234\n",
        "np.random.seed(seed_value) # set numpy seed\n",
        "torch.manual_seed(seed_value); # set pytorch seed CPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-nTM2_slVtk"
      },
      "source": [
        "## 3. Autoencoder Neural Networks (AENNs) Assignments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07mXCnNIaSAB"
      },
      "source": [
        "### 3.1 Dataset Download and Data Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngxp3En7aSAB"
      },
      "source": [
        "Nowadays, organizations accelerate the digitization and reconfiguration of business processes [4] affecting in particular Accounting Information Systems (AIS) or more general Enterprise Resource Planning (ERP) systems.\n",
        "\n",
        "Steadily, these systems collect vast quantities of electronic evidence at an almost atomic level. This observation holds in particular for the journal entries of an organization recorded in its general ledger and sub-ledger accounts. SAP, one of the most prominent ERP software providers, estimates that approx. 76% of the world's transaction revenue touches one of their systems [5].\n",
        "\n",
        "The illustration in **Figure 1** depicts a hierarchical view of an Accounting Information System (AIS) recording process and journal entry information in designated database tables. In the context of fraud examinations, the data collected by such systems may contain valuable traces of a potential fraud scheme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVi2JiAnaSAB"
      },
      "source": [
        "<img align=\"middle\" style=\"max-width: 700px; height: auto\" src=\"accounting.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-qx9r6aaSAB"
      },
      "source": [
        "**Figure 1:** Hierarchical view of an Accounting Information System (AIS) that records distinct layers of abstraction, namely (1) the business process information, (2) the accounting information as well as the (3) technical journal entry information in designated database tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fo_2K6AaSAB"
      },
      "source": [
        "In this section of the lab notebook, we will conduct a descriptive analysis of the lab's financial dataset. Furthermore, we will apply some necessary pre-processing steps to train a deep neural network. The lab is based on a derivation of the **\"Synthetic Financial Dataset For Fraud Detection\"** by Lopez-Rojas [6] available via the Kaggle predictive modeling and analytics competitions platform that can be obtained using the following link: https://www.kaggle.com/ntnu-testimon/paysim1.\n",
        "\n",
        "Let's start loading the dataset and investigate its structure and attributes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpVV3HphaSAB"
      },
      "source": [
        "# load the dataset into the notebook kernel\n",
        "url = 'https://raw.githubusercontent.com/HSG-AIML/LabGSERM/master/lab_06/data/fraud_dataset_v2.csv'\n",
        "ori_dataset = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7qLKptcaSAB"
      },
      "source": [
        "Let's also check the dataset dimensionalities for completeness: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBveiiEjaSAB"
      },
      "source": [
        "# inspect the datasets dimensionalities\n",
        "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
        "print('[LOG {}] transactional dataset of {} rows and {} columns retreived.'.format(now, ori_dataset.shape[0], ori_dataset.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aQLNBpVaSAC"
      },
      "source": [
        "#### 3.1.1 Initial Data and Attribute Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeC1JvLVaSAC"
      },
      "source": [
        "We augmented the dataset and renamed the attributes to mimic a real-world dataset that one usually observes in SAP-ERP systems as part of SAP's Finance and Cost controlling (FICO) module. \n",
        "\n",
        "The dataset contains a subset of in total seven categorical and two numerical attributes available in the FICO BKPF (containing the posted journal entry headers) and BSEG (containing the posted journal entry segments) tables. Please, find below a list of the individual attributes as well as a brief description of their respective semantics:\n",
        "\n",
        ">- `BELNR`: the accounting document number,\n",
        ">- `BUKRS`: the company code,\n",
        ">- `BSCHL`: the posting key,\n",
        ">- `HKONT`: the posted general ledger account,\n",
        ">- `PRCTR`: the posted profit center,\n",
        ">- `WAERS`: the currency key,\n",
        ">- `KTOSL`: the general ledger account key,\n",
        ">- `DMBTR`: the amount in the local currency,\n",
        ">- `WRBTR`: the amount in the document currency.\n",
        "\n",
        "Let's also have a closer look into the top 10 rows of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcciZJU3aSAC"
      },
      "source": [
        "# inspect top rows of dataset\n",
        "ori_dataset.head(10) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsfHRECFaSAC"
      },
      "source": [
        "You may also have noticed the attribute `label` in the data. We will use this field throughout the lab to evaluate the quality of our trained models. The field describes the true nature of each transaction of either being a **regular** transaction (denoted by `regular`) or an **anomaly** (denoted by `global` and `local`). Let's have a closer look into the distribution of the regular vs. anomalous transactions in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578fevF1aSAC"
      },
      "source": [
        "# number of anomalies vs. regular transactions\n",
        "ori_dataset.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sOxVFTcaSAC"
      },
      "source": [
        "Ok, the statistic reveals that similar to real-world scenarios, we are facing a highly \"unbalanced\" dataset. Overall, the dataset contains only a small fraction of **100 (0.018%)** anomalous transactions. While the 100 anomalous entries encompass **70 (0.013%)** \"global\" anomalies and **30 (0.005%)** \"local\" anomalies as introduced in section 1.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fJAYpwgaSAC"
      },
      "source": [
        "# remove the \"ground-truth\" label information for the following steps of the lab\n",
        "label = ori_dataset.pop('label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXAksi26aSAC"
      },
      "source": [
        "#### 3.1.2 Pre-Processing of Categorical Transaction Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "memf1htJaSAC"
      },
      "source": [
        "From the initial data assessment above, we can observe that the majority of attributes recorded in AIS- and ERP-systems correspond to categorical (discrete) attribute values, e.g. the posting date, the general ledger account, the posting type, the currency. Let's have a more detailed look into the distribution of two dataset attributes, namely (1) the posting key `BSCHL` as well as (2) the general ledger account `HKONT`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4TNwm2baSAC"
      },
      "source": [
        "# prepare to plot posting key and general ledger account side by side\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "fig.set_figwidth(20)\n",
        "\n",
        "# plot the distribution of the posting key attribute\n",
        "g = sns.countplot(x=ori_dataset['BSCHL'], ax=ax[0])\n",
        "\n",
        "# set axis labels\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
        "g.set_xlabel('BSCHL Value', fontsize=18)\n",
        "g.set_ylabel('Value Count', fontsize=18)\n",
        "\n",
        "# set plot title\n",
        "g.set_title('Distribution of the \\'Posting Key\\' attribute values', fontsize=20)\n",
        "\n",
        "# plot the distribution of the general ledger attribute\n",
        "g = sns.countplot(x=ori_dataset['HKONT'], ax=ax[1])\n",
        "\n",
        "# set axis labels\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
        "g.set_xlabel('HKONT Value', fontsize=18)\n",
        "g.set_ylabel('Value Count', fontsize=18)\n",
        "\n",
        "# set plot title\n",
        "g.set_title('Distribution of the \\'General Ledger\\' attribute values', fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5XMiVhPaSAC"
      },
      "source": [
        "Unfortunately, neural networks are, in general, not designed to be trained directly on categorical data and require the attributes to be trained on to be numeric. One simple way to meet this requirement is by applying a technique referred to as **\"one-hot\" encoding**. Using this encoding technique, we will derive a numerical representation of each of the categorical attribute values. One-hot encoding creates new binary columns for each categorical attribute value present in the original data. \n",
        "\n",
        "Let's have a look at the example shown in **Figure 2** below. The **categorical attribute “Receiver”** below contains the names \"John,\" \"Timur\" and \"Marco.\" We \"one-hot\" encode the names by creating a separate binary column for each possible name-value observable in the \"Receiver\" column. Now, we encode for each transaction that contains the value \"John\" in the \"Receiver\" column this observation with 1.0 in the newly created \"John\" column and 0.0 in all other generated name columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-jrwsYaSAD"
      },
      "source": [
        "<img align=\"middle\" style=\"max-width: 600px; height: auto\" src=\"encoding.png\">\n",
        "\n",
        "**Figure 2:** Exemplary one-hot encoding of the distinct `Receiver` attribute values into specific binary (\"one-hot) columns. Thereby, each attribute value observable in the dataset results in a separate column. The column value `1.0` denotes the occurance of the attribute value in the corresponding journal entry. In contrast the column value `0.0` indicates the absence of the attribute value in the corresponding journal entry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTJ7A5h-aSAD"
      },
      "source": [
        "Using this technique will \"one-hot\" encode the six categorical attributes in the original transactional dataset. This can be achieved using the `get_dummies()` function available in the Pandas data science library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgc4RciyaSAD"
      },
      "source": [
        "# select categorical attributes to be \"one-hot\" encoded\n",
        "categorical_attr_names = ['KTOSL', 'PRCTR', 'BSCHL', 'HKONT']\n",
        "\n",
        "# encode categorical attributes into a binary one-hot encoded representation \n",
        "ori_dataset_cat_processed = pd.get_dummies(ori_dataset[categorical_attr_names])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iogu41vkaSAD"
      },
      "source": [
        "Finally, let's inspect the encoding of 10 sample transactions to see if the encoding was accomplished successfully;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qYlZTeFaSAD"
      },
      "source": [
        "# inspect encoded sample transactions\n",
        "ori_dataset_cat_processed.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Pzz6GTaSAD"
      },
      "source": [
        "#### 3.1.3 Pre-Processing of Numerical Transaction Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrZTGXUQaSAD"
      },
      "source": [
        "Let's now inspect the distributions of the two numerical attributes contained in the transactional dataset namely, the (1) local currency amount `DMBTR` and the (2) document currency amount `WRBTR`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-gWbOmgaSAD"
      },
      "source": [
        "# plot the log-scaled \"DMBTR\" as well as the \"WRBTR\" attribute value distribution\n",
        "fig, ax = plt.subplots(1,2)\n",
        "fig.set_figwidth(20)\n",
        "\n",
        "# plot distribution of the local amount attribute\n",
        "g = sns.distplot(ori_dataset['DMBTR'].tolist(), ax=ax[0])\n",
        "\n",
        "# set axis labels\n",
        "g.set_xlabel('DMBTR Value', fontsize=18)\n",
        "g.set_ylabel('Value Count', fontsize=18)\n",
        "\n",
        "# set plot title\n",
        "g.set_title('Distribution of the \\'Local Amount\\' attribute values', fontsize=20)\n",
        "\n",
        "# plot distribution of the document amount attribute\n",
        "g = sns.distplot(ori_dataset['WRBTR'].tolist(), ax=ax[1])\n",
        "\n",
        "# set axis labels\n",
        "g.set_xlabel('WRBTR Value', fontsize=18)\n",
        "g.set_ylabel('Value Count', fontsize=18)\n",
        "\n",
        "# set plot title\n",
        "g.set_title('Distribution of the \\'Foreign Amount\\' attribute values', fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7ntY2-DaSAD"
      },
      "source": [
        "As expected, it can be observed that for both attributes, the distributions of amount values are **heavy-tailed**. In order to approach faster a potential global minimum scaling and normalization of numerical input values is good practice. Therefore, we first log-scale both variables and second min-max normalize the scaled amounts to the interval [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maVYBOxjaSAD"
      },
      "source": [
        "# select the 'DMBTR' and 'WRBTR' attribute\n",
        "numeric_attr_names = ['DMBTR', 'WRBTR']\n",
        "\n",
        "# add a small epsilon to eliminate zero values from data for log scaling\n",
        "numeric_attr = ori_dataset[numeric_attr_names] + 1e-7\n",
        "\n",
        "# log scale the 'DMBTR' and 'WRBTR' attribute values\n",
        "numeric_attr = numeric_attr.apply(np.log)\n",
        "\n",
        "# normalize all numeric attributes to the range [0,1]\n",
        "ori_dataset_num_processed = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30qsf_I8aSAD"
      },
      "source": [
        "Let's now visualize the log-scaled and min-max normalized distributions of both attributes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebf9TRShaSAD"
      },
      "source": [
        "# plot the log-scaled \"DMBTR\" as well as the \"WRBTR\" attribute value distribution\n",
        "fig, ax = plt.subplots(1,2)\n",
        "fig.set_figwidth(20)\n",
        "\n",
        "# plot distribution of the local amount attribute\n",
        "g = sns.distplot(ori_dataset_num_processed['DMBTR'].tolist(), ax=ax[0])\n",
        "\n",
        "# set axis labels\n",
        "g.set_xlabel('DMBTR Value', fontsize=18)\n",
        "g.set_ylabel('Value Count', fontsize=18)\n",
        "\n",
        "# set plot title\n",
        "g.set_title('Distribution of the \\'Local Amount\\' attribute values', fontsize=20)\n",
        "\n",
        "# plot distribution of the document amount attribute\n",
        "g = sns.distplot(ori_dataset_num_processed['WRBTR'].tolist(), ax=ax[1])\n",
        "\n",
        "# set axis labels\n",
        "g.set_xlabel('WRBTR Value', fontsize=18)\n",
        "g.set_ylabel('Value Count', fontsize=18)\n",
        "\n",
        "# set plot title\n",
        "g.set_title('Distribution of the \\'Foreign Amount\\' attribute values', fontsize=20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdubhQNiaSAD"
      },
      "source": [
        "#### 3.1.4 Merge Categorical and Numerical Transaction Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "becFFkqeaSAD"
      },
      "source": [
        "Finally, we merge both pre-processed numerical and categorical attributes into a single dataset that we will use for training our deep autoencoder neural network (explained an implemented in the following section 2):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU74jVKBaSAE"
      },
      "source": [
        "# merge categorical and numeric subsets\n",
        "ori_subset_transformed = pd.concat([ori_dataset_cat_processed, ori_dataset_num_processed], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiylcP6SaSAE"
      },
      "source": [
        "Now, let's again have a look at the dimensionality of the dataset after we applied the distinct pre-processing steps to the attributes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veJ5vRodaSAE"
      },
      "source": [
        "# inspect final dimensions of pre-processed transactional data\n",
        "ori_subset_transformed.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_7jYKjnaSAE"
      },
      "source": [
        "Ok, upon completion of all the pre-processing steps (excl. the exercises), we should end up with an encoded dataset consisting of a total number of **533,009 records** (rows) and **384 encoded attributes** (columns). Let's keep the number number of columns in mind since it will define the dimensionality of the input- and output-layer of our deep autoencoder network, which we will now implement in the following section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EDtdmb0aSAL"
      },
      "source": [
        "### 3.2 Autoencoder Neural Network (AENN) Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRW2N1ofaSAL"
      },
      "source": [
        "We recommend you to try the following exercises as part of the lab, based on the notebook you have seen:\n",
        "\n",
        "**1. Add of the two additional journal entry attributes `WAERS` and `BUKRS`.**\n",
        "\n",
        ">Pre-process the journal entry data and learn an `AENN model` including also the attributes `WAERS` and `BUKRS`. Therefore, (1) plot and inspect the distribution of the distinct values observable for both attributes, (2) encode the values of the attributes using the `get_dummies()` method provided by the Pandas library, and (3) merge your encoding results with the `ori_subset_transformed` data frame (upon successful merge the one-hot encoded dataset should encompass a total dimensionality of 638 instead of 384 columns). Ultimately, train an `AENN model` including both attributes and evaluate its anomaly detection performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTLQ7uFfaSAM"
      },
      "source": [
        "#### Step 1. pre-process the journal entry data, including the WAERS and BURKS attributes (steps above) #############\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 2. define and init neural network architecture #############################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 3. define loss and training hyperparameters ################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 4. run model training ######################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 5. run model evaluation ####################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGVr1vMfaSAM"
      },
      "source": [
        "**2. Apply a `dropout` throughout the network training.**\n",
        "\n",
        ">Set the `dropout` probability to `0.2` (20%) and re-start the training procedure. What impact do you observe in terms of training performance / reconstruction loss?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbBLoyGqaSAM"
      },
      "source": [
        "#### Step 1. define and init neural network architecture, with dropout ###############################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 2. define loss, training hyperparameters and dataloader ####################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 3. run model training ######################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 4. run model evaluation ####################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdGpLBugaSAM"
      },
      "source": [
        "**3. Train and evaluate a `shallow` autoencoder model.**\n",
        "\n",
        "> The lab model architecture resulted in a good anomaly detection accuracy. Let's see how the reconstruction performance change if **several of the hidden layers** will be removed. First, adjust the encoder and decoder model definitions from the lab accordingly (you may want to use the code snippets shown below). Then, follow all the instructions for training from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnm-DHNMaSAM"
      },
      "source": [
        "# implementation of the shallow encoder network \n",
        "# containing only a single layer\n",
        "class shallow_encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(encoder, self).__init__()\n",
        "\n",
        "        # specify layer 1 - in 618, out 3\n",
        "        self.encoder_L1 = nn.Linear(in_features=ori_subset_transformed.shape[1], out_features=3, bias=True) # add linearity \n",
        "        nn.init.xavier_uniform_(self.encoder_L1.weight) # init weights according to [9]\n",
        "        self.encoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        # define forward pass through the network\n",
        "        x = self.encoder_R1(self.encoder_L1(x)) # don't apply dropout to the AE bottleneck\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZXQc-LeaSAM"
      },
      "source": [
        "# implementation of the shallow decoder network \n",
        "# containing only a single layer\n",
        "class shallow_decoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(decoder, self).__init__()\n",
        "\n",
        "        # specify layer 1 - in 3, out 618\n",
        "        self.decoder_L1 = nn.Linear(in_features=3, out_features=ori_subset_transformed.shape[1], bias=True) # add linearity \n",
        "        nn.init.xavier_uniform_(self.decoder_L1.weight)  # init weights according to [9]\n",
        "        self.decoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # define forward pass through the network\n",
        "        x = self.decoder_R1(self.decoder_L1(x)) # don't apply dropout to the AE output\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5btA6mW2NDyV"
      },
      "source": [
        "#### Step 1. define and init neural network architecture #############################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 2. define loss, training hyperparameters and dataloader ####################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 3. run model training ######################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 4. run model evaluation ####################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}