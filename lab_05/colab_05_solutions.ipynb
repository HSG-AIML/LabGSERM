{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0cP5Z789_rr"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
    "\n",
    "##  Lab 05 - \"Convolutional Neural Networks (CNNs)\" Assignments\n",
    "\n",
    "EMBA 58/59 - W8/3 - \"AI Coding for Executives\", University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rno8GqfC9_rz"
   },
   "source": [
    "In the last lab we learned how to enhance vanilla Artificial Neural Networks (ANNs) using `PyTorch` to classify even more complex images. Therefore, we used a special type of deep neural network referred to **Convolutional Neural Networks (CNNs)**. CNNs encompass the ability to take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments. But before we do so let's start with another motivational video by NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# NVIDIA: \"Official Intro | GTC 2020 | I AM AI\"\n",
    "YouTubeVideo('e2_hsjpTi4w', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r93JK2DH9_r0"
   },
   "source": [
    "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW6dySzs9_r1"
   },
   "source": [
    "## 1. Assignment Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uzc9Xr69_r1"
   },
   "source": [
    "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
    "\n",
    "> 1. Understand the basic concepts, intuitions and major building blocks of **Convolutional Neural Networks (CNNs)**.\n",
    "> 2. Know how to **implement and to train a CNN** to learn a model of tiny image data.\n",
    "> 3. Understand how to apply such a learned model to **classify images** images based on their content into distinct categories.\n",
    "> 4. Know how to **interpret and visualize** the model's classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPRKkkig9_r2"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mZL4i6W9_r2"
   },
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn` and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9cwWtab9_r2"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import os, urllib, io\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrB_51t89_r3"
   },
   "source": [
    "Import Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH6LhB_q9_r3"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning library\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfgYux7K9_r3"
   },
   "source": [
    "Import the sklearn classification metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFptYrnr9_r4"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJJ5kfaf9_r4"
   },
   "source": [
    "Import Python plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usAgsocK9_r4"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZft6q1B9_r5"
   },
   "source": [
    "Enable notebook matplotlib inline plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXnX3zt_9_r5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn2cf5SqJ2m9"
   },
   "source": [
    "Import Google's GDrive connector and mount your GDrive directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2rj2ThhJ3sA"
   },
   "outputs": [],
   "source": [
    "# import the Google Colab GDrive connector\n",
    "from google.colab import drive\n",
    "\n",
    "# mount GDrive inside the Colab notebook\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-58e-iazJ8Aq"
   },
   "source": [
    "Create a structure of Colab Notebook sub-directories inside of GDrive to store (1) the data as well as (2) the trained neural network models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtB6DCWjJ-gD"
   },
   "outputs": [],
   "source": [
    "# create Colab Notebooks directory\n",
    "notebook_directory = '/content/drive/MyDrive/Colab Notebooks'\n",
    "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
    "\n",
    " # create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = '/content/drive/MyDrive/Colab Notebooks/data'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    " # create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = '/content/drive/MyDrive/Colab Notebooks/models'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcYgp4Gl9_r6"
   },
   "source": [
    "Set a random `seed` value to obtain reproducable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdbqEjHb9_r7"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpKQNDr09_r7"
   },
   "source": [
    "Google Colab provides the use of free GPUs for running notebooks. However, if you just execute this notebook as is, it will use your device's CPU. To run the lab on a GPU, got to `Runtime` > `Change runtime type` and set the Runtime type to `GPU` in the drop-down. Running this lab on a CPU is fine, but you will find that GPU computing is faster. *CUDA* indicates that the lab is being run on GPU.\n",
    "\n",
    "Enable GPU computing by setting the `device` flag and init a `CUDA` seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAFg7INc9_r7"
   },
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-7Ve4-_9_r7"
   },
   "source": [
    "Let's determine if we have access to a GPU provided by e.g. Google's COLab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCpTB9x59_r8"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Networks (CNNs) Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH1CSkRV9_r8"
   },
   "source": [
    "### 3.1 CIFAR-10 Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWDn7IQE9_r8"
   },
   "source": [
    "The **CIFAR-10 database** (**C**anadian **I**nstitute **F**or **A**dvanced **R**esearch) is a collection of images that are commonly used to train machine learning and computer vision algorithms. The database is widely used to conduct computer vision research using machine learning and deep learning methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awuRyFMd9_r8"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 500px; height: 500px\" src=\"cifar10.png\">\n",
    "\n",
    "(Source: https://www.kaggle.com/c/cifar-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjdI5VVN9_r8"
   },
   "source": [
    "Further details on the dataset can be obtained via: *Krizhevsky, A., 2009. \"Learning Multiple Layers of Features from Tiny Images\",  \n",
    "( https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf ).\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaD13bmO9_r9"
   },
   "source": [
    "The CIFAR-10 database contains **60,000 color images** (50,000 training images and 10,000 validation images). The size of each image is 32 by 32 pixels. The collection of images encompasses 10 different classes that represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Let's define the distinct classs for further analytics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WlB2yXu9_r-"
   },
   "outputs": [],
   "source": [
    "cifar10_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRslZNGV9_r-"
   },
   "source": [
    "Thereby the dataset contains 6,000 images for each of the ten classes. The CIFAR-10 is a straightforward dataset that can be used to teach a computer how to recognize objects in images.\n",
    "\n",
    "Let's download, transform and inspect the training images of the dataset. Therefore, we first will define the directory we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2Bmhc-c9_r-"
   },
   "outputs": [],
   "source": [
    "train_path = data_directory + '/train_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6AGBP_K9_r_"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_-Zs4EU9_sA"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform training images\n",
    "cifar10_train_data = torchvision.datasets.CIFAR10(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g79sdHOw9_sA"
   },
   "source": [
    "Verify the volume of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiKFBLrI9_sA"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWcoDhr_9_sC"
   },
   "source": [
    "Let's now decide on where we want to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKFBcveC9_sC"
   },
   "outputs": [],
   "source": [
    "eval_path = data_directory + '/eval_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB5OpV4z9_sC"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-OOVFFs9_sD"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform validation images\n",
    "cifar10_eval_data = torchvision.datasets.CIFAR10(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF4VrcHG9_sD"
   },
   "source": [
    "Let's also verfify the volume of validation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhZRDL4X9_sD"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9Xivz3j9_sD"
   },
   "source": [
    "### 3.2 Convolutional Neural Network (CNN) Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nswYOXvk9_r0"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgqmaa129_sZ"
   },
   "source": [
    "We recommend you to try the following exercises as part of the self-coding session:\n",
    "\n",
    "**Exercise 1: Train the neural network architecture of the lab with increased learning rate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Increase the learning rate of the network training to a value of **0.1** (instead of currently 0.001) and re-run the network training for 10 training epochs. Load and evaluate the model exhibiting the lowest training loss. What kind of behavior in terms of loss convergence and prediction accuracy can be observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx4C87LF9_sZ"
   },
   "outputs": [],
   "source": [
    "#### Step 1. define neural network architecture ######################################################################\n",
    "\n",
    "# implement the CIFAR10Net network architecture\n",
    "class CIFAR10Net(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "        \n",
    "        # specify convolution layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # define max-pooling layer 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # specify convolution layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # define max-pooling layer 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # specify fc layer 1 - in 16 * 5 * 5, out 120\n",
    "        self.linear1 = nn.Linear(16 * 5 * 5, 120, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity\n",
    "        \n",
    "        # specify fc layer 2 - in 120, out 84\n",
    "        self.linear2 = nn.Linear(120, 84, bias=True) # the linearity W*x+b\n",
    "        self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "        \n",
    "        # specify fc layer 3 - in 84, out 10\n",
    "        self.linear3 = nn.Linear(84, 10) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # high-level feature learning via convolutional layers\n",
    "        \n",
    "        # define conv layer 1 forward pass\n",
    "        x = self.pool1(self.relu1(self.conv1(images)))\n",
    "        \n",
    "        # define conv layer 2 forward pass\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # feature flattening\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # combination of feature learning via non-linear layers\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x\n",
    "    \n",
    "model = CIFAR10Net()\n",
    "\n",
    "#### Step 2. define loss, training hyperparameters & dataloader ############################################################\n",
    "\n",
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# specify the training parameters\n",
    "num_epochs = 20 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches\n",
    "\n",
    "# define training dataloader\n",
    "cifar10_train_dataloader = torch.utils.data.DataLoader(cifar10_train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "#### Step 3. run model training ######################################################################################\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the CIFAR10 model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(cifar10_train_dataloader):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # set filename of actual model\n",
    "    model_name = 'cifar10_model_epoch_{}.pth'.format(str(epoch))\n",
    "\n",
    "    # save current model to GDrive models directory\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "\n",
    "#### Step 4. run model evaluation ####################################################################################\n",
    "\n",
    "# define eval dataloader\n",
    "cifar10_eval_dataloader = torch.utils.data.DataLoader(cifar10_eval_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "# determine model predictions\n",
    "predictions = torch.argmax(model(iter(cifar10_eval_dataloader).next()[0]), dim=1)\n",
    "\n",
    "# determine classification accuracy\n",
    "metrics.accuracy_score(cifar10_eval_data.targets, predictions.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNBnGfwU9_sa"
   },
   "source": [
    "**2. Evaluation of \"shallow\" vs. \"deep\" neural network architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In addition to the architecture of the lab notebook, evaluate further (more **shallow** as well as more **deep**) neural network architectures by either **removing or adding convolutional layers** to the network. Train a model (using the architectures you selected) for at least **20 training epochs**. Analyze the prediction performance of the trained models in terms of training time and prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-zirkqH9_sa"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "#### Step 1. define neural network architecture ######################################################################\n",
    "\n",
    "# implement the CIFAR10Net network architecture\n",
    "class CIFAR10Net(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "        \n",
    "        # specify convolution layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # define max-pooling layer 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # specify convolution layer 2\n",
    "        # self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        # define max-pooling layer 2\n",
    "        # self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # specify fc layer 1 - in 6 * 14 * 14, out 120\n",
    "        self.linear1 = nn.Linear(6 * 14 * 14, 120, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity\n",
    "        \n",
    "        # specify fc layer 2 - in 120, out 84\n",
    "        self.linear2 = nn.Linear(120, 84, bias=True) # the linearity W*x+b\n",
    "        self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "        \n",
    "        # specify fc layer 3 - in 84, out 10\n",
    "        self.linear3 = nn.Linear(84, 10) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # high-level feature learning via convolutional layers\n",
    "        \n",
    "        # define conv layer 1 forward pass\n",
    "        x = self.pool1(self.relu1(self.conv1(images)))\n",
    "        \n",
    "        # define conv layer 2 forward pass\n",
    "        # x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # feature flattening\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = x.view(-1, 6 * 14 * 14)\n",
    "        \n",
    "        # combination of feature learning via non-linear layers\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x\n",
    "    \n",
    "model = CIFAR10Net()\n",
    "\n",
    "#### Step 2. define loss, training hyperparameters & dataloader ############################################################\n",
    "\n",
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# specify the training parameters\n",
    "num_epochs = 20 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches\n",
    "\n",
    "# define training dataloader\n",
    "cifar10_train_dataloader = torch.utils.data.DataLoader(cifar10_train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "#### Step 3. run model training ######################################################################################\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the CIFAR10 model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(cifar10_train_dataloader):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # set filename of actual model\n",
    "    model_name = 'cifar10_model_epoch_{}.pth'.format(str(epoch))\n",
    "\n",
    "    # save current model to GDrive models directory\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "\n",
    "#### Step 4. run model evaluation ####################################################################################\n",
    "\n",
    "# define eval dataloader\n",
    "cifar10_eval_dataloader = torch.utils.data.DataLoader(cifar10_eval_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "# determine model predictions\n",
    "predictions = torch.argmax(model(iter(cifar10_eval_dataloader).next()[0]), dim=1)\n",
    "\n",
    "# determine classification accuracy\n",
    "metrics.accuracy_score(cifar10_eval_data.targets, predictions.detach())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eW6dySzs9_r1",
    "iPRKkkig9_r2",
    "XH1CSkRV9_r8",
    "B9Xivz3j9_sD",
    "rUeMEeHa9_sJ",
    "sWU9hWb_9_sO",
    "N8NnkvgF9_sR",
    "038JB6i49_sZ",
    "ST0oDfsq9_sk"
   ],
   "name": "ml_lab_05.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.39999389648438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
