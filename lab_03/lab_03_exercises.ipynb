{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_03_exercises.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D0Jnx-Ljt8lK",
        "CZaa0qAnt8lY",
        "E5MbyOLHVzo5",
        "mMSfpCPvt8l4",
        "g_6MsT_JYZLu"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIziVsRIO6d1"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGwNwDKEt8lG"
      },
      "source": [
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
        "\n",
        "##  Lab 03 - \"Supervised Machine Learning\" Assignments\n",
        "\n",
        "GSERM'21 course \"Deep Learning: Fundamentals and Applications\", University of St. Gallen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjUA7XZyh7DI"
      },
      "source": [
        "The lab environment of the \"Deep Learning: Fundamentals and Applications\" GSERM course at the University of St. Gallen (HSG) is based on Jupyter Notebooks (https://jupyter.org), which allow to perform a variety of statistical evaluations and data analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_TW0Piak3gL"
      },
      "source": [
        "In the last lab we learned how to implement, train, and apply our first **Machine Learning** models, namely the Gaussian **Naive-Bayes (NB)** and the **Support Vectore Machine (SVM)** classifiers. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Br5f8mEt8lK"
      },
      "source": [
        "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Jnx-Ljt8lK"
      },
      "source": [
        "## 1. Assignment Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybF-i5mQt8lL"
      },
      "source": [
        "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
        "\n",
        "> 1. Know how to setup a **notebook or \"pipeline\"** that solves a simple supervised classification task.\n",
        "> 2. Recognize the **data elements** needed to train and evaluate a supervised machine learning classifier. \n",
        "> 3. Understand how a Gaussian **Naive-Bayes (NB)** classifier can be trained and evaluated.\n",
        "> 4. Understand how a **Suppport Vector Machine (SVM)** classifier can be trained and evaluated.\n",
        "> 5. Train and evaluate **machine learning models** using Python's `scikit-learn` library.\n",
        "> 6. Understand how to **evaluate** and **interpret** the classification results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svq48yIQt8lM"
      },
      "source": [
        "Before we start let's watch a motivational video:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyE587hOt8lN"
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "# OpenAI: \"Solving Rubik's Cube with a Robot Hand\"\n",
        "# YouTubeVideo('x4O8pojMF0w', width=800, height=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZaa0qAnt8lY"
      },
      "source": [
        "## 2. Setup of the Analysis Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yTCqemyt8la"
      },
      "source": [
        "Similarly to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. In this lab will use the `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` and the `Seaborn` library. Let's import the libraries by the execution of the statements below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ShseCwt8lb"
      },
      "source": [
        "# import the numpy, scipy and pandas data science library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.stats import norm\n",
        "\n",
        "# import sklearn data and data pre-processing libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import sklearn naive.bayes classifier library\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# import sklearn support vector classifier (svc) library\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# import sklearn classification evaluation library\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# import matplotlib data visualization library\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFnbcu4yt8le"
      },
      "source": [
        "Enable inline Jupyter notebook plotting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLbxWoZit8lf"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_mWNdpVUJgJ"
      },
      "source": [
        "Ignore potential library warnings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhtZlKmUG3_"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFqwDkYt8ln"
      },
      "source": [
        "Use the 'Seaborn' plotting style in all subsequent visualizations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMH7Y9-Ht8lo"
      },
      "source": [
        "plt.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z2tRqzFt8lu"
      },
      "source": [
        "Set random seed of all our experiments - this insures reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzE1FzaSt8lu"
      },
      "source": [
        "random_seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5MbyOLHVzo5"
      },
      "source": [
        "## 3. Data Download, Assessment and Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0gpZzk5t8l5"
      },
      "source": [
        "### 3.1 Dataset Download and Data Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilrWTyMt8l6"
      },
      "source": [
        "The **Iris Dataset** is a classic and straightforward dataset often used as a \"Hello World\" example in multi-class classification. This data set consists of measurements taken from three different types of iris flowers (referred to as **Classes**),  namely the Iris Setosa, the Iris Versicolour and the Iris Virginica, and their respective measured petal and sepal length (referred to as **Features**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlF-VYuOt8l7"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 700px; height: auto\" src=\"iris_dataset.png\">\n",
        "\n",
        "(Source: http://www.lac.inpe.br/~rafael.santos/Docs/R/CAP394/WholeStory-Iris.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBHv_Rbrt8l8"
      },
      "source": [
        "In total, the dataset consists of **150 samples** (50 samples taken per class) as well as their corresponding **4 different measurements** taken for each sample. Please, find below the list of the individual measurements:\n",
        "\n",
        ">- `Sepal length (cm)`\n",
        ">- `Sepal width (cm)`\n",
        ">- `Petal length (cm)`\n",
        ">- `Petal width (cm)`\n",
        "\n",
        "Further details of the dataset can be obtained from the following puplication: *Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).\"*\n",
        "\n",
        "Let's load the dataset and conduct a preliminary data assessment: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CtBrJGut8l9"
      },
      "source": [
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE2PbwClt8mB"
      },
      "source": [
        "Print and inspect the names of the four features contained in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLzNDo8t8mF"
      },
      "source": [
        "iris.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIvnl8Qct8mK"
      },
      "source": [
        "Determine and print the feature dimensionality of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq6gZN-1t8mM"
      },
      "source": [
        "iris.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwiIRMR_t8mW"
      },
      "source": [
        "Determine and print the class label dimensionality of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tayVqRQOt8mX"
      },
      "source": [
        "iris.target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoQlbXs_t8md"
      },
      "source": [
        "Print and inspect the names of the three classes contained in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R__ACqSct8me"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwqoNt8gt8mh"
      },
      "source": [
        "Let's briefly envision how the feature information of the dataset is collected and presented in the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCgJtdiot8mi"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"feature_collection.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD3SBLxzt8mi"
      },
      "source": [
        "Let's inspect the top five feature rows of the Iris Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kju1z4Cft8mk"
      },
      "source": [
        "pd.DataFrame(iris.data, columns=iris.feature_names).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P62AsvZ8t8mr"
      },
      "source": [
        "Let's also inspect the top five class labels of the Iris Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNjr0a5Dt8ms"
      },
      "source": [
        "pd.DataFrame(iris.target, columns=[\"class\"]).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxz--vVdt8mu"
      },
      "source": [
        "Let's now conduct a more in depth data assessment. Therefore, we plot the feature distributions of the Iris dataset according to their respective class memberships as well as the features pairwise relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWofkTgQt8mw"
      },
      "source": [
        "Pls. note that we use Python's **Seaborn** library to create such a plot referred to as **Pairplot**. The Seaborn library is a powerful data visualization library based on the Matplotlib. It provides a great interface for drawing informative statstical graphics (https://seaborn.pydata.org). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmfO2-yit8mx"
      },
      "source": [
        "# init the plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# load the dataset also available in seaborn\n",
        "iris_plot = sns.load_dataset(\"iris\")\n",
        "\n",
        "# plot a pairplot of the distinct feature distributions\n",
        "sns.pairplot(iris_plot, diag_kind='hist', hue='species');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ugPoMiQt8m4"
      },
      "source": [
        "It can be observed from the created Pairplot, that most of the feature measurements that correspond to flower class \"setosa\" exhibit a nice **linear seperability** from the feature measurements of the remaining flower classes. In addition, the flower classes \"versicolor\" and \"virginica\" exhibit a commingled and **non-linear seperability** across all the measured feature distributions of the Iris Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTWFzhhFt8m4"
      },
      "source": [
        "### 3.2 Dataset Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTBwny8Dt8m5"
      },
      "source": [
        "To understand and evaluate the performance of any trained **supervised machine learning** model, it is good practice to divide the dataset into a **training set** (the fraction of data records solely used for training purposes) and a **evaluation set** (the fraction of data records solely used for evaluation purposes). Please note that the **evaluation set** will never be shown to the model as part of the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFU5ijYat8m6"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 500px; height: auto\" src=\"train_eval_dataset.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN25KKcvt8m6"
      },
      "source": [
        "We set the fraction of evaluation records to **30%** of the original dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPFvlzS6t8m7"
      },
      "source": [
        "eval_fraction = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FkQME8Ut8m9"
      },
      "source": [
        "Randomly split the dataset into training set and evaluation set using sklearn's `train_test_split` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF7m6KMSt8m9"
      },
      "source": [
        "# 70% training and 30% evaluation\n",
        "x_train, x_eval, y_train, y_eval = train_test_split(iris.data, iris.target, test_size=eval_fraction, random_state=random_seed, stratify=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T37IuZHIt8m_"
      },
      "source": [
        "Evaluate the dimensionality of the training dataset $x^{train}$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9i0U2uzt8nA"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqJitVsit8nC"
      },
      "source": [
        "Evaluate the dimensionality of the evaluation dataset $x^{eval}$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeVTeCNat8nD"
      },
      "source": [
        "x_eval.shape, y_eval.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMSfpCPvt8l4"
      },
      "source": [
        "## 4. Gaussian \"Naive-Bayes\" (NB) Classification Assignments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ-KsINqt8qh"
      },
      "source": [
        "We recommend you to try the following exercises as part of the lab:\n",
        "\n",
        "**1. Train and evaluate the prediction accuracy of different train- vs. eval-data ratios.**\n",
        "\n",
        "> Change the ratio of training data vs. evaluation data to 30%/70% (currently 70%/30%), fit your model and calculate the new classification accuracy. Subsequently, repeat the experiment a second time using a 10%/90% fraction of training data/evaluation data. What can be observed in both experiments in terms of classification accuracy? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL_44Y-qt8qi"
      },
      "source": [
        "# ***************************************************\n",
        "# INSERT YOUR CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVDiTWD0t8qo"
      },
      "source": [
        "**2. Calculate the true-positive as well as the false-positive rate of the Iris versicolor vs. virginica.**\n",
        "\n",
        "> Calculate the true-positive rate as well as false-positive rate of (1) the experiment exhibiting a 30%/70% ratio of training data vs. evaluation data and (2) the experiment exhibiting a 10%/90% ratio of training data vs. evaluation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v418nuq5t8qp"
      },
      "source": [
        "# ***************************************************\n",
        "# INSERT YOUR CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_6MsT_JYZLu"
      },
      "source": [
        "## 5. Support Vector Machine (SVM) Classification Assignments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSrJAgMCFkjM"
      },
      "source": [
        "We recommend you to try the following exercises as part of the lab:\n",
        "\n",
        "**1. Train and evaluate the prediction accuracy of SVM models trained with different hyperparameters.**\n",
        "\n",
        "> Change the kernel function $\\phi$ of the SVM to a polynomial kernel, fit your model and calculate the new classification accuracy on the IRIS dataset. Subsequently, repeat similar experiment with different SVM hyperparameter setups by changing the value of $C$, $\\gamma$ and the kernel function $\\phi$. What pattern can be observed by the distinct hyperparameter setups in terms of classification accuracy? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6TDKB5FkjN"
      },
      "source": [
        "# ***************************************************\n",
        "# INSERT YOUR CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M342FTuVFkjN"
      },
      "source": [
        "**2. Train and evaluate the prediction accuracy of SVM models using different or additional features.**\n",
        "\n",
        "> Fix the hyperparameters of the SVM and evalute the classification accuracy on the FashionMNIST dataset using different features. For example, evaluate the prediction accuracy that can be derived based on a set of Scale-Invariant Feature Transform (SIFT) features. Or the combination of HOG and SIFT features. Will the consideration of additional features improve you classification accuracy?\n",
        "\n",
        "More information on the FashionMNIST dataset: visit Zalando research's [github page](https://github.com/zalandoresearch/fashion-mnist)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atVeqqFJFkjN"
      },
      "source": [
        "# ***************************************************\n",
        "# INSERT YOUR CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}